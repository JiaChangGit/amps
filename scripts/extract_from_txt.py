#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°‡äº”å€‹ *_prediction_3_result.txt è½‰æˆ Excelï¼Œ
ä¸¦æ‰¾å‡ºåœ¨è‡³å°‘ã€Œå…©å€‹ tailã€åŒæ™‚å‡ºç¾çš„ packet_IDã€‚
"""

import os
import re
from collections import Counter
from typing import Dict, Iterable, Set, Any

import pandas as pd

# ------------------------------------------------------------
# è®€æª”è¨­å®š
# ------------------------------------------------------------
TXT_FILES = [
    "PT_prediction_3_result.txt",
    "DBT_prediction_3_result.txt",
    "KSet_prediction_3_result.txt",
    "DT_prediction_3_result.txt",
    "MT_prediction_3_result.txt",
]

PATTERN = re.compile(r"Packet (\d+)\s+RealTime\(ns\) ([\d.]+)")
OUTPUT_XLSX = "AVG_D_Results_BySheet.xlsx"

# ------------------------------------------------------------
# å°å·¥å…·ï¼šæ‰¾å‡ºè‡³å°‘å‡ºç¾åœ¨ N å€‹é›†åˆçš„å…ƒç´ 
# ------------------------------------------------------------
def find_common_ids(
    tail_dict: Dict[str, pd.DataFrame],
    *,
    key: str = "packet_ID",
    min_occurrence: int = 2,
    labels: Iterable[str] = ("PT", "DBT", "KSet", "DT", "MT"),
) -> Set[Any]:
    """
    å›å‚³ã€Œè‡³å°‘åŒæ™‚å‡ºç¾åœ¨ min_occurrence å€‹ DataFrame[key]ã€çš„å…ƒç´ é›†åˆã€‚
    """
    counter: Counter[Any] = Counter()
    for label in labels:
        ids = set(tail_dict.get(label, pd.DataFrame()).get(key, []))
        counter.update(ids)
    return {pid for pid, cnt in counter.items() if cnt >= min_occurrence}


# ------------------------------------------------------------
# ä¸»æµç¨‹ï¼šè§£æ txt â†’ DataFrame â†’ Excel
# ------------------------------------------------------------
tail_dict: Dict[str, pd.DataFrame] = {}

with pd.ExcelWriter(OUTPUT_XLSX) as writer:
    for txt_path in TXT_FILES:
        with open(txt_path, "r", encoding="utf-8") as f:
            lines = f.readlines()

        # æŠ½å– (packet_ID, TimeR)
        records = [
            (int(m.group(1)), float(m.group(2)))
            for line in lines
            if (m := PATTERN.search(line))
        ]
        df = pd.DataFrame(records, columns=["packet_ID", "TimeR (ns)"])

        # ä¾ AVG è¨­é–€æª»ï¼ˆ2Ã—AVGï¼‰
        avg_time = df["TimeR (ns)"].mean()
        threshold = 2 * avg_time
        print(f"[{txt_path}] AVG = {avg_time:.2f} ns, Threshold = {threshold:.2f} ns")

        # ç¯© tail
        df_tail = df[df["TimeR (ns)"] >= threshold].copy()

        # æ¨™è¨˜ä¾†æº
        base_name = os.path.basename(txt_path).replace("_prediction_3_result.txt", "")
        df_tail["Source"] = base_name

        # å¯«å…¥ Excelï¼ˆæœªæ’åºèˆ‡å·²æ’åºï¼‰
        df_tail.to_excel(writer, index=False, sheet_name=f"{base_name}_Unsorted")
        df_tail.sort_values("TimeR (ns)").reset_index(drop=True).to_excel(
            writer, index=False, sheet_name=f"{base_name}_Sorted"
        )

        # å­˜åˆ°å­—å…¸ä»¥ä¾¿å¾ŒçºŒäº¤é›†é‹ç®—
        tail_dict[base_name] = df_tail

    # --------------------------------------------------------
    # æ‰¾å‡ºã€Œè‡³å°‘è½åœ¨ 2 å€‹ tailã€çš„ packet_ID
    # --------------------------------------------------------
    common_ids = find_common_ids(tail_dict, min_occurrence=2)

    print(f"âœ… è‡³å°‘å‡ºç¾åœ¨ 2 å€‹ tail çš„ packet_ID æ•¸é‡ï¼š{len(common_ids)}")
    if common_ids:
        preview = sorted(common_ids)[:20]
        print("å‰ 20 å€‹ packet_IDï¼š", preview)

    # å¯«å…¥ Excel Sheet
    pd.DataFrame(sorted(common_ids), columns=["Common packet_ID"]).to_excel(
        writer, index=False, sheet_name="Common_in_Tail"
    )

print(f"ğŸ“„ å…¨éƒ¨çµæœå·²å¯«å…¥ï¼š{OUTPUT_XLSX}")
